{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046, 7)\n",
      "(292, 7)\n"
     ]
    }
   ],
   "source": [
    "mask = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "training_set = df[mask]\n",
    "\n",
    "testing_set = df[~mask]\n",
    "\n",
    "print(training_set.shape)\n",
    "print(testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training and test sets to be used later\n",
    "training_set.to_csv(\"../../data/training_set.csv\")\n",
    "testing_set.to_csv(\"../../data/testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the feature columns from the target column\n",
    "feature_columns = [\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]\n",
    "target_column = \"charges\"\n",
    "\n",
    "X_train = training_set[feature_columns]\n",
    "y_train = training_set[target_column]\n",
    "\n",
    "X_test = testing_set[feature_columns]\n",
    "y_test = testing_set[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# loading the preprocessing pipeline we built in the previous notebook\n",
    "transformer = joblib.load(\"../model_files/transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/entityset/entity.py:600: UserWarning: Using first column as index. To change this, specify the index parameter\n",
      "  warnings.warn((\"Using first column as index. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19.  , 27.9 ,  0.  , ...,  1.  ,  0.  ,  3.  ],\n",
       "       [18.  , 33.77,  1.  , ...,  0.  ,  1.  ,  2.  ],\n",
       "       [28.  , 33.  ,  3.  , ...,  0.  ,  1.  ,  2.  ],\n",
       "       ...,\n",
       "       [18.  , 31.92,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [18.  , 36.85,  0.  , ...,  0.  ,  0.  ,  2.  ],\n",
       "       [21.  , 25.8 ,  0.  , ...,  0.  ,  0.  ,  3.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the column transformer\n",
    "\n",
    "features = transformer.fit_transform(X_train)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find an Optimal Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot_regressor = TPOTRegressor(generations=50,\n",
    "                               population_size=100,\n",
    "                               random_state=42,\n",
    "                               cv=5,\n",
    "                               n_jobs=8,\n",
    "                               verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post2 of tpot is outdated. Version 0.11.6.post3 was released 2 days ago.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=5100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -21796561.75896593\n",
      "\n",
      "Generation 2 - Current best internal CV score: -21796561.75896593\n",
      "\n",
      "Generation 3 - Current best internal CV score: -21509873.747133274\n",
      "\n",
      "Generation 4 - Current best internal CV score: -21509873.747133274\n",
      "\n",
      "Generation 5 - Current best internal CV score: -21509873.747133274\n",
      "\n",
      "Generation 6 - Current best internal CV score: -21509873.747133274\n",
      "\n",
      "Generation 7 - Current best internal CV score: -21509873.747133274\n",
      "\n",
      "Generation 8 - Current best internal CV score: -21449180.000772525\n",
      "\n",
      "Generation 9 - Current best internal CV score: -21420290.508588605\n",
      "\n",
      "Generation 10 - Current best internal CV score: -21403008.310245067\n",
      "\n",
      "Generation 11 - Current best internal CV score: -21174464.457369022\n",
      "\n",
      "Generation 12 - Current best internal CV score: -21174464.457369022\n",
      "\n",
      "Generation 13 - Current best internal CV score: -21174464.457369022\n",
      "\n",
      "Generation 14 - Current best internal CV score: -21106233.729438014\n",
      "\n",
      "Generation 15 - Current best internal CV score: -21106233.729438014\n",
      "\n",
      "Generation 16 - Current best internal CV score: -21073412.11467626\n",
      "\n",
      "Generation 17 - Current best internal CV score: -21073412.11467626\n",
      "\n",
      "Generation 18 - Current best internal CV score: -21073412.11467626\n",
      "\n",
      "Generation 19 - Current best internal CV score: -21073412.11467626\n",
      "\n",
      "Generation 20 - Current best internal CV score: -21073412.11467626\n",
      "\n",
      "Generation 21 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 22 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 23 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 24 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 25 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 26 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 27 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 28 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 29 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 30 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 31 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 32 - Current best internal CV score: -21011827.60945706\n",
      "\n",
      "Generation 33 - Current best internal CV score: -20923060.11733312\n",
      "\n",
      "Generation 34 - Current best internal CV score: -20923060.11733312\n",
      "\n",
      "Generation 35 - Current best internal CV score: -20923060.11733312\n",
      "\n",
      "Generation 36 - Current best internal CV score: -20921804.900674257\n",
      "\n",
      "Generation 37 - Current best internal CV score: -20921804.900674257\n",
      "\n",
      "Generation 38 - Current best internal CV score: -20921804.900674257\n",
      "\n",
      "Generation 39 - Current best internal CV score: -20921804.900674257\n",
      "\n",
      "Generation 40 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 41 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 42 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 43 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 44 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 45 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 46 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 47 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 48 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 49 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Generation 50 - Current best internal CV score: -20917853.24759181\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(PolynomialFeatures(RobustScaler(AdaBoostRegressor(ZeroCount(input_matrix), learning_rate=0.001, loss=linear, n_estimators=100)), degree=2, include_bias=False, interaction_only=False), bootstrap=False, max_features=0.6500000000000001, min_samples_leaf=19, min_samples_split=15, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "tpot_regressor = tpot_regressor.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now that we have an optimal pipeline created by TPOT we will be adding our own preprocessors to it. To do this we'll need to have an unfitted pipeline object, we don't have that right now because the TPOTRegressor pipeline has been fitted. \n",
    "\n",
    "To get an unfitted pipeline we'll ask TPOT to export the pipeline as a python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_regressor.export(\"../model_files/tpot_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code that will create the pipeline that was found by the TPOT package, we'll execute it here to make sure that we can instantiate the Pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "tpot_pipeline = make_pipeline(\n",
    "    ZeroCount(),\n",
    "    StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001, loss=\"linear\", n_estimators=100)),\n",
    "    RobustScaler(),\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "    ExtraTreesRegressor(bootstrap=False, max_features=0.6500000000000001, min_samples_leaf=19, min_samples_split=15, n_estimators=100)\n",
    ")\n",
    "\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(tpot_pipeline.steps, 'random_state', 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can build the same pipeline that was found by the TPOT package, we'll add our own preprocessors to the pipeline. This will ensure that the final pipeline will accept the features in the original dataset and will process the features correctly.\n",
    "\n",
    "We'll compose all of the pipelines we created above into one Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"transformer\", transformer),\n",
    "    (\"tpot_pipeline\", tpot_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/entityset/entity.py:600: UserWarning: Using first column as index. To change this, specify the index parameter\n",
      "  warnings.warn((\"Using first column as index. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('dfs_pipeline',\n",
       "                                                  Pipeline(steps=[('dfs_transformer',\n",
       "                                                                   DFSTransformer(ignore_variables={'Transactions': ['sex',\n",
       "                                                                                                                     'smoker',\n",
       "                                                                                                                     'region']},\n",
       "                                                                                  target_entity='Transactions',\n",
       "                                                                                  trans_primitives=['add_numeric',\n",
       "                                                                                                    'subtract_numeric',\n",
       "                                                                                                    'multiply_numeric',\n",
       "                                                                                                    'divide_numeric',\n",
       "                                                                                                    'greater_than',\n",
       "                                                                                                    'less_...\n",
       "                                 ('stackingestimator',\n",
       "                                  StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001,\n",
       "                                                                                n_estimators=100,\n",
       "                                                                                random_state=42))),\n",
       "                                 ('robustscaler', RobustScaler()),\n",
       "                                 ('polynomialfeatures',\n",
       "                                  PolynomialFeatures(include_bias=False)),\n",
       "                                 ('extratreesregressor',\n",
       "                                  ExtraTreesRegressor(max_features=0.6500000000000001,\n",
       "                                                      min_samples_leaf=19,\n",
       "                                                      min_samples_split=15,\n",
       "                                                      random_state=42))]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score:  0.8436187523922933\n",
      "mean squared error:  19433336.664826013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "r2_score = r2_score(y_test, predictions)\n",
    "mean_squared_error = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(\"r2 score: \", r2_score)\n",
    "print(\"mean squared error: \", mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model With Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25421.74473706])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the ColumnTransformer\n",
    "test_df = pd.DataFrame([[65, \"male\", 12.5, 0, \"yes\", \"southwest\"]], \n",
    "                       columns =[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]) \n",
    "\n",
    "\n",
    "result = model.predict(test_df)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model_files/model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"../model_files/model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
