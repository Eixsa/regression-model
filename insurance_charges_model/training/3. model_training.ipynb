{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1054, 7)\n",
      "(284, 7)\n"
     ]
    }
   ],
   "source": [
    "mask = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "training_set = df[mask]\n",
    "\n",
    "testing_set = df[~mask]\n",
    "\n",
    "print(training_set.shape)\n",
    "print(testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training and test sets to be used later\n",
    "training_set.to_csv(\"../../data/training_set.csv\")\n",
    "testing_set.to_csv(\"../../data/testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the feature columns from the target column\n",
    "feature_columns = [\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]\n",
    "target_column = \"charges\"\n",
    "\n",
    "X_train = training_set[feature_columns]\n",
    "y_train = training_set[target_column]\n",
    "\n",
    "X_test = testing_set[feature_columns]\n",
    "y_test = testing_set[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the preprocessing pipeline we built in the previous notebook\n",
    "transformer = joblib.load(\"../model_files/transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/synthesis/deep_feature_synthesis.py:156: UserWarning: Only one entity in entityset, changing max_depth to 1 since deeper features cannot be created\n",
      "  warnings.warn(\"Only one entity in entityset, changing max_depth to \"\n",
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/entityset/entity.py:452: UserWarning: Using first column as index. To change this, specify the index parameter\n",
      "  warnings.warn((\"Using first column as index. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19.   , 27.9  ,  0.   , ...,  1.   ,  0.   ,  3.   ],\n",
       "       [33.   , 22.705,  0.   , ...,  0.   ,  1.   ,  1.   ],\n",
       "       [32.   , 28.88 ,  0.   , ...,  0.   ,  1.   ,  1.   ],\n",
       "       ...,\n",
       "       [57.   , 25.74 ,  2.   , ...,  0.   ,  0.   ,  2.   ],\n",
       "       [50.   , 30.97 ,  3.   , ...,  0.   ,  1.   ,  1.   ],\n",
       "       [21.   , 25.8  ,  0.   , ...,  0.   ,  0.   ,  3.   ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the column transformer\n",
    "features = transformer.fit_transform(X_train)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find an Optimal Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_regressor = TPOTRegressor(generations=50,\n",
    "                               population_size=100,\n",
    "                               random_state=42,\n",
    "                               cv=5,\n",
    "                               n_jobs=8,\n",
    "                               verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/5100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -20181615.829195686\n",
      "\n",
      "Generation 2 - Current best internal CV score: -20181615.829195686\n",
      "\n",
      "Generation 3 - Current best internal CV score: -19848332.164544817\n",
      "\n",
      "Generation 4 - Current best internal CV score: -19848332.164544817\n",
      "\n",
      "Generation 5 - Current best internal CV score: -19848332.164544817\n",
      "\n",
      "Generation 6 - Current best internal CV score: -19848332.164544817\n",
      "\n",
      "Generation 7 - Current best internal CV score: -19816504.27026009\n",
      "\n",
      "Generation 8 - Current best internal CV score: -19727874.78911667\n",
      "\n",
      "Generation 9 - Current best internal CV score: -19727874.78911667\n",
      "\n",
      "Generation 10 - Current best internal CV score: -19727874.78911667\n",
      "\n",
      "Generation 11 - Current best internal CV score: -19727874.78911667\n",
      "\n",
      "Generation 12 - Current best internal CV score: -19727874.78911667\n",
      "\n",
      "Generation 13 - Current best internal CV score: -19701596.956555426\n",
      "\n",
      "Generation 14 - Current best internal CV score: -19701596.956555426\n",
      "\n",
      "Generation 15 - Current best internal CV score: -19700053.32929636\n",
      "\n",
      "Generation 16 - Current best internal CV score: -19700053.32929636\n",
      "\n",
      "Generation 17 - Current best internal CV score: -19700053.32929636\n",
      "\n",
      "Generation 18 - Current best internal CV score: -19668972.031186257\n",
      "\n",
      "Generation 19 - Current best internal CV score: -19668972.031186257\n",
      "\n",
      "Generation 20 - Current best internal CV score: -19644192.170632605\n",
      "\n",
      "Generation 21 - Current best internal CV score: -19597800.04271979\n",
      "\n",
      "Generation 22 - Current best internal CV score: -19597800.04271979\n",
      "\n",
      "Generation 23 - Current best internal CV score: -19597800.04271979\n",
      "\n",
      "Generation 24 - Current best internal CV score: -19597800.04271979\n",
      "\n",
      "Generation 25 - Current best internal CV score: -19595994.228280164\n",
      "\n",
      "Generation 26 - Current best internal CV score: -19595994.228280164\n",
      "\n",
      "Generation 27 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 28 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 29 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 30 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 31 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 32 - Current best internal CV score: -19581984.016653717\n",
      "\n",
      "Generation 33 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 34 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 35 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 36 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 37 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 38 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 39 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 40 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 41 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 42 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 43 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 44 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 45 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 46 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 47 - Current best internal CV score: -19575080.298895888\n",
      "\n",
      "Generation 48 - Current best internal CV score: -19575007.77756657\n",
      "\n",
      "Generation 49 - Current best internal CV score: -19575007.77756657\n",
      "\n",
      "Generation 50 - Current best internal CV score: -19575007.77756657\n",
      "\n",
      "Best pipeline: RandomForestRegressor(ElasticNetCV(SelectFwe(input_matrix, alpha=0.037), l1_ratio=0.9500000000000001, tol=1e-05), bootstrap=True, max_features=0.8, min_samples_leaf=18, min_samples_split=14, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "tpot_regressor = tpot_regressor.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now that we have an optimal pipeline created by TPOT we will be adding our own preprocessors to it. To do this we'll need to have an unfitted pipeline object, we don't have that right now because the TPOTRegressor pipeline has been fitted. \n",
    "\n",
    "To get an unfitted pipeline we'll ask TPOT to export the pipeline as a python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_regressor.export(\"../model_files/tpot_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code that will create the pipeline that was found by the TPOT package, we'll execute it here to make sure that we can instantiate the Pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFwe, f_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Average CV score on the training set was: -19575007.77756657\n",
    "tpot_pipeline = make_pipeline(\n",
    "    SelectFwe(score_func=f_regression, alpha=0.037),\n",
    "    StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.9500000000000001, tol=1e-05)),\n",
    "    RandomForestRegressor(bootstrap=True, max_features=0.8, min_samples_leaf=18, min_samples_split=14, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(tpot_pipeline.steps, 'random_state', 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can build the same pipeline that was found by the TPOT package, we'll add our own preprocessors to the pipeline. This will ensure that the final pipeline will accept the features in the original dataset and will process the features correctly.\n",
    "\n",
    "We'll compose all of the pipelines we created above into one Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"transformer\", transformer),\n",
    "    (\"tpot_pipeline\", tpot_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/synthesis/deep_feature_synthesis.py:156: UserWarning: Only one entity in entityset, changing max_depth to 1 since deeper features cannot be created\n",
      "  warnings.warn(\"Only one entity in entityset, changing max_depth to \"\n",
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/featuretools/entityset/entity.py:452: UserWarning: Using first column as index. To change this, specify the index parameter\n",
      "  warnings.warn((\"Using first column as index. \"\n",
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:302: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/brian/Code/regression-model/venv/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:307: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('dfs_pipeline',\n",
       "                                                  Pipeline(steps=[('dfs_transformer',\n",
       "                                                                   DFSTransformer(ignore_variables={'Transactions': ['sex',\n",
       "                                                                                                                     'smoker',\n",
       "                                                                                                                     'region']},\n",
       "                                                                                  target_entity='Transactions',\n",
       "                                                                                  trans_primitives=['add_numeric',\n",
       "                                                                                                    'subtract_numeric',\n",
       "                                                                                                    'multiply_numeric',\n",
       "                                                                                                    'divide_numeric',\n",
       "                                                                                                    'greater_than',\n",
       "                                                                                                    'less_...\n",
       "                ('tpot_pipeline',\n",
       "                 Pipeline(steps=[('selectfwe',\n",
       "                                  SelectFwe(alpha=0.037,\n",
       "                                            score_func=<function f_regression at 0x13ac28790>)),\n",
       "                                 ('stackingestimator',\n",
       "                                  StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.9500000000000001,\n",
       "                                                                           random_state=42,\n",
       "                                                                           tol=1e-05))),\n",
       "                                 ('randomforestregressor',\n",
       "                                  RandomForestRegressor(max_features=0.8,\n",
       "                                                        min_samples_leaf=18,\n",
       "                                                        min_samples_split=14,\n",
       "                                                        random_state=42))]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score:  0.8408772880472506\n",
      "mean squared error:  22226429.889209867\n",
      "mean absolute error:  2539.0184656719302\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"r2 score: \", r2)\n",
    "print(\"mean squared error: \", mse)\n",
    "print(\"mean absolute error: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model With Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23656.57334195])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the ColumnTransformer\n",
    "test_df = pd.DataFrame([[65, \"male\", 12.5, 0, \"yes\", \"southwest\"]],\n",
    "                       columns=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])\n",
    "\n",
    "\n",
    "result = model.predict(test_df)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model_files/model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"../model_files/model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
